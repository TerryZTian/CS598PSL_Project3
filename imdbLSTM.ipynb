{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.autograph.impl.api.do_not_convert(func=None)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from keras.layers import Dense, LSTM,Embedding, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# removing the html tags\n",
    "def clean_html(text):\n",
    "    clean=re.compile('<.*?>')\n",
    "    cleantext=re.sub(clean,'',text)\n",
    "    return cleantext\n",
    "    \n",
    "# first round of cleaning\n",
    "def clean_text1(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('\\[.*?\\]','',text)\n",
    "    text=re.sub('[%s]'%re.escape(string.punctuation),'',text)\n",
    "    text=re.sub('\\w*\\d\\w*','',text)\n",
    "    return text\n",
    "\n",
    "# second round of cleaning\n",
    "def clean_text2(text):\n",
    "    text=re.sub('[''\"\",,,]','',text)\n",
    "    text=re.sub('\\n','',text)\n",
    "    return text\n",
    "    \n",
    "cleaned_html=lambda x:clean_html(x)\n",
    "cleaned1=lambda x:clean_text1(x)\n",
    "cleaned2=lambda x:clean_text2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Fold:1 <<<<<\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f78e7972c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f78e7972c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.7869WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f78949a0840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f78949a0840> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 465s 1s/step - loss: 0.4492 - accuracy: 0.7869 - val_loss: 0.9209 - val_accuracy: 0.5664\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 441s 1s/step - loss: 0.2993 - accuracy: 0.8788 - val_loss: 0.9614 - val_accuracy: 0.5564\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 430s 1s/step - loss: 0.2638 - accuracy: 0.8951 - val_loss: 1.2232 - val_accuracy: 0.5498\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 422s 1s/step - loss: 0.2223 - accuracy: 0.9134 - val_loss: 1.1950 - val_accuracy: 0.5582\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 422s 1s/step - loss: 0.2114 - accuracy: 0.9188 - val_loss: 1.0508 - val_accuracy: 0.5560\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 418s 1s/step - loss: 0.1919 - accuracy: 0.9281 - val_loss: 1.1010 - val_accuracy: 0.5575\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 414s 1s/step - loss: 0.1681 - accuracy: 0.9367 - val_loss: 1.2976 - val_accuracy: 0.5512\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 411s 1s/step - loss: 0.1585 - accuracy: 0.9393 - val_loss: 1.4064 - val_accuracy: 0.5561\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 413s 1s/step - loss: 0.1413 - accuracy: 0.9455 - val_loss: 1.4703 - val_accuracy: 0.5554\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 412s 1s/step - loss: 0.1291 - accuracy: 0.9522 - val_loss: 1.6246 - val_accuracy: 0.5532\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f78949a0488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f78949a0488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> Fold:2 <<<<<\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7887e70ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7887e70ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4631 - accuracy: 0.7746WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7893aed6a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7893aed6a8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 417s 1s/step - loss: 0.4631 - accuracy: 0.7746 - val_loss: 0.9379 - val_accuracy: 0.6029\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 415s 1s/step - loss: 0.3081 - accuracy: 0.8774 - val_loss: 0.8974 - val_accuracy: 0.5814\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 414s 1s/step - loss: 0.2582 - accuracy: 0.8980 - val_loss: 0.8956 - val_accuracy: 0.5952\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 421s 1s/step - loss: 0.2586 - accuracy: 0.8944 - val_loss: 0.8857 - val_accuracy: 0.5996\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 414s 1s/step - loss: 0.2332 - accuracy: 0.9104 - val_loss: 1.0661 - val_accuracy: 0.5985\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 417s 1s/step - loss: 0.1928 - accuracy: 0.9266 - val_loss: 1.0348 - val_accuracy: 0.5963\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 418s 1s/step - loss: 0.1810 - accuracy: 0.9315 - val_loss: 1.0449 - val_accuracy: 0.5941\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 415s 1s/step - loss: 0.1451 - accuracy: 0.9462 - val_loss: 1.1753 - val_accuracy: 0.5930\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 401s 1s/step - loss: 0.1342 - accuracy: 0.9498 - val_loss: 1.3599 - val_accuracy: 0.5846\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 407s 1s/step - loss: 0.1282 - accuracy: 0.9534 - val_loss: 1.4378 - val_accuracy: 0.5912\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f78e5eac2f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f78e5eac2f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> Fold:3 <<<<<\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f78d758ff28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f78d758ff28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.7895WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f78c7989400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f78c7989400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 414s 1s/step - loss: 0.4446 - accuracy: 0.7895 - val_loss: 0.7451 - val_accuracy: 0.5852\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 413s 1s/step - loss: 0.3059 - accuracy: 0.8763 - val_loss: 0.9152 - val_accuracy: 0.5690\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 416s 1s/step - loss: 0.2566 - accuracy: 0.8994 - val_loss: 1.0068 - val_accuracy: 0.5758\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 414s 1s/step - loss: 0.2184 - accuracy: 0.9160 - val_loss: 1.3523 - val_accuracy: 0.5832\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 417s 1s/step - loss: 0.2655 - accuracy: 0.8946 - val_loss: 1.0121 - val_accuracy: 0.5779\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 431s 1s/step - loss: 0.1950 - accuracy: 0.9251 - val_loss: 1.2248 - val_accuracy: 0.5766\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 422s 1s/step - loss: 0.1722 - accuracy: 0.9372 - val_loss: 1.1767 - val_accuracy: 0.5579\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 431s 1s/step - loss: 0.1590 - accuracy: 0.9417 - val_loss: 1.1962 - val_accuracy: 0.5674\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 445s 1s/step - loss: 0.1632 - accuracy: 0.9395 - val_loss: 1.2037 - val_accuracy: 0.5782\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 495s 1s/step - loss: 0.1297 - accuracy: 0.9535 - val_loss: 1.4555 - val_accuracy: 0.5690\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7884a83400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7884a83400> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> Fold:4 <<<<<\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f78949a0048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f78949a0048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4482 - accuracy: 0.7796WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7883f459d8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7883f459d8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 466s 1s/step - loss: 0.4482 - accuracy: 0.7796 - val_loss: 0.9153 - val_accuracy: 0.5846\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 429s 1s/step - loss: 0.3444 - accuracy: 0.8568 - val_loss: 0.9068 - val_accuracy: 0.5928\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 425s 1s/step - loss: 0.3055 - accuracy: 0.8742 - val_loss: 0.8305 - val_accuracy: 0.5938\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 425s 1s/step - loss: 0.2510 - accuracy: 0.9008 - val_loss: 1.0218 - val_accuracy: 0.5977\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 425s 1s/step - loss: 0.2180 - accuracy: 0.9138 - val_loss: 1.0152 - val_accuracy: 0.5972\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 425s 1s/step - loss: 0.2065 - accuracy: 0.9209 - val_loss: 1.0065 - val_accuracy: 0.5940\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 424s 1s/step - loss: 0.1795 - accuracy: 0.9324 - val_loss: 1.1127 - val_accuracy: 0.5983\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 429s 1s/step - loss: 0.1582 - accuracy: 0.9392 - val_loss: 1.1323 - val_accuracy: 0.5903\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 423s 1s/step - loss: 0.1540 - accuracy: 0.9418 - val_loss: 1.1692 - val_accuracy: 0.5939\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 425s 1s/step - loss: 0.1427 - accuracy: 0.9464 - val_loss: 1.5096 - val_accuracy: 0.5952\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f789fbb38c8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f789fbb38c8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> Fold:5 <<<<<\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f78d73b4a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f78d73b4a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.7832WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f78844849d8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f78844849d8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 413s 1s/step - loss: 0.4568 - accuracy: 0.7832 - val_loss: 0.8126 - val_accuracy: 0.5987\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 407s 1s/step - loss: 0.4027 - accuracy: 0.8304 - val_loss: 1.0512 - val_accuracy: 0.5744\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 404s 1s/step - loss: 0.2976 - accuracy: 0.8798 - val_loss: 0.9832 - val_accuracy: 0.5814\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 398s 1s/step - loss: 0.2500 - accuracy: 0.9020 - val_loss: 1.0791 - val_accuracy: 0.5764\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 395s 1s/step - loss: 0.2288 - accuracy: 0.9104 - val_loss: 1.0149 - val_accuracy: 0.5633\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 396s 1s/step - loss: 0.1990 - accuracy: 0.9245 - val_loss: 1.0750 - val_accuracy: 0.5657\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 392s 1s/step - loss: 0.1906 - accuracy: 0.9289 - val_loss: 1.1645 - val_accuracy: 0.5812\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 389s 995ms/step - loss: 0.1688 - accuracy: 0.9366 - val_loss: 1.2027 - val_accuracy: 0.5682\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 393s 1s/step - loss: 0.1474 - accuracy: 0.9466 - val_loss: 1.3696 - val_accuracy: 0.5731\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 390s 997ms/step - loss: 0.1324 - accuracy: 0.9524 - val_loss: 1.5137 - val_accuracy: 0.5771\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f78949a00d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f78949a00d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> All folds are done <<<<<\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(1,6):\n",
    "    print(f'>>>>> Fold:{i} <<<<<')\n",
    "    folderName = 'split_' + str(i)\n",
    "    train_filename = folderName + '/' + 'train.tsv'\n",
    "    test_filename = folderName + '/' + 'test.tsv'\n",
    "    test_y_filename = folderName + '/' + 'test_y.tsv'\n",
    "\n",
    "    train_data = pd.read_csv(train_filename,sep='\\t', header=0)\n",
    "    train_data['review']=pd.DataFrame(train_data.review.apply(cleaned_html))\n",
    "    train_data['review']=pd.DataFrame(train_data.review.apply(cleaned1))\n",
    "    train_data['review']=pd.DataFrame(train_data.review.apply(cleaned2))\n",
    "\n",
    "    train_y = train_data['sentiment']\n",
    "    train_features = train_data.copy()\n",
    "    train_features = train_features.drop(['sentiment'],axis=1)\n",
    "\n",
    "    test_data = pd.read_csv(test_filename,sep='\\t', header=0)\n",
    "    test_data['review']=pd.DataFrame(test_data.review.apply(cleaned_html))\n",
    "    test_data['review']=pd.DataFrame(test_data.review.apply(cleaned1))\n",
    "    test_data['review']=pd.DataFrame(test_data.review.apply(cleaned2))\n",
    "\n",
    "    test_features = test_data['review']\n",
    "    # print(test_data.head(5))\n",
    "    # print(test_data.shape)\n",
    "    test_y_data = pd.read_csv(test_y_filename,sep='\\t', header=0)\n",
    "\n",
    "    max_features=5000\n",
    "    tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "    tokenizer.fit_on_texts(train_data['review'].values)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(train_data['review'].values)\n",
    "    X_train = pad_sequences(X_train,maxlen=600)\n",
    "    Y_train = pd.get_dummies(train_data['sentiment']).values\n",
    "    # Y_train = train_data['sentiment']\n",
    "\n",
    "    tokenizer.fit_on_texts(test_data['review'].values)\n",
    "    X_test = tokenizer.texts_to_sequences(test_data['review'].values)\n",
    "    X_test = pad_sequences(X_test,maxlen=600)\n",
    "    Y_test = pd.get_dummies(test_y_data['sentiment']).values\n",
    "    # Y_test = test_y_data['sentiment']\n",
    "\n",
    "    embed_dim = 128\n",
    "    lstm_out = 128\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_dim,input_length = X_train.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.4))\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    batch_size = 64\n",
    "\n",
    "    # X_train = tf.autograph.experimental.do_not_convert(X_train)\n",
    "    # Y_train = tf.autograph.experimental.do_not_convert(Y_train)\n",
    "\n",
    "    # X_test = tf.autograph.experimental.do_not_convert(X_test)\n",
    "    # Y_test = tf.autograph.experimental.do_not_convert(Y_test)\n",
    "    # model = tf.autograph.experimental.do_not_convert(model)\n",
    "    model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size,validation_data=(X_test,Y_test),verbose=True)\n",
    "    pred_Y = model.predict(X_test)\n",
    "    auc = roc_auc_score(Y_test, pred_Y,average='micro')\n",
    "    res.append(auc)\n",
    "    print('>>>>> Running is done <<<<<')\n",
    "print('>>>>> All folds are done <<<<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean AUC:0.60129185312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_auc = np.mean(res)\n",
    "\n",
    "print(f'mean AUC:{mean_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_features, embed_dim,input_length = X_train.shape[1]))\n",
    "model2.add(SpatialDropout1D(0.4))\n",
    "model2.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(Dense(2,activation='softmax'))\n",
    "model2.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Fold:1 <<<<<\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.7438WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f78949a0d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f78949a0d08> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "391/391 [==============================] - 382s 977ms/step - loss: 0.5386 - accuracy: 0.7438 - val_loss: 0.7557 - val_accuracy: 0.5534\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 396s 1s/step - loss: 0.4107 - accuracy: 0.8218 - val_loss: 1.0417 - val_accuracy: 0.5369\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 414s 1s/step - loss: 0.3095 - accuracy: 0.8728 - val_loss: 1.0355 - val_accuracy: 0.5710\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 417s 1s/step - loss: 0.2511 - accuracy: 0.9005 - val_loss: 1.0246 - val_accuracy: 0.5641\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 411s 1s/step - loss: 0.2353 - accuracy: 0.9075 - val_loss: 1.2888 - val_accuracy: 0.5473\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 419s 1s/step - loss: 0.2142 - accuracy: 0.9193 - val_loss: 1.1812 - val_accuracy: 0.5632\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 425s 1s/step - loss: 0.1867 - accuracy: 0.9288 - val_loss: 1.1236 - val_accuracy: 0.5688\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 417s 1s/step - loss: 0.1702 - accuracy: 0.9354 - val_loss: 1.2238 - val_accuracy: 0.5690\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 417s 1s/step - loss: 0.1541 - accuracy: 0.9433 - val_loss: 1.3106 - val_accuracy: 0.5768\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 413s 1s/step - loss: 0.1325 - accuracy: 0.9500 - val_loss: 1.5580 - val_accuracy: 0.5614\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f78d73b4620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f78d73b4620> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> Fold:2 <<<<<\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 403s 1s/step - loss: 0.6036 - accuracy: 0.6760 - val_loss: 0.7821 - val_accuracy: 0.6010\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 395s 1s/step - loss: 0.4024 - accuracy: 0.8249 - val_loss: 0.7892 - val_accuracy: 0.6260\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 401s 1s/step - loss: 0.3377 - accuracy: 0.8563 - val_loss: 0.9438 - val_accuracy: 0.5994\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 761s 2s/step - loss: 0.2725 - accuracy: 0.8904 - val_loss: 0.8741 - val_accuracy: 0.6064\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 374s 958ms/step - loss: 0.2230 - accuracy: 0.9144 - val_loss: 1.1345 - val_accuracy: 0.6052\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 387s 989ms/step - loss: 0.2141 - accuracy: 0.9180 - val_loss: 1.2097 - val_accuracy: 0.5981\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 398s 1s/step - loss: 0.1747 - accuracy: 0.9330 - val_loss: 1.1620 - val_accuracy: 0.6008\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 369s 944ms/step - loss: 0.1464 - accuracy: 0.9460 - val_loss: 1.3221 - val_accuracy: 0.6028\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 370s 947ms/step - loss: 0.1318 - accuracy: 0.9501 - val_loss: 1.3838 - val_accuracy: 0.5975\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 373s 954ms/step - loss: 0.1206 - accuracy: 0.9562 - val_loss: 1.3506 - val_accuracy: 0.5921\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> Fold:3 <<<<<\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 377s 964ms/step - loss: 0.5924 - accuracy: 0.6881 - val_loss: 0.7114 - val_accuracy: 0.6150\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 547s 1s/step - loss: 0.3329 - accuracy: 0.8621 - val_loss: 0.8751 - val_accuracy: 0.6112\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 407s 1s/step - loss: 0.2565 - accuracy: 0.8993 - val_loss: 0.9022 - val_accuracy: 0.5996\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 410s 1s/step - loss: 0.2171 - accuracy: 0.9154 - val_loss: 1.0074 - val_accuracy: 0.6033\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 397s 1s/step - loss: 0.1863 - accuracy: 0.9301 - val_loss: 1.0297 - val_accuracy: 0.6013\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 394s 1s/step - loss: 0.1619 - accuracy: 0.9396 - val_loss: 1.1622 - val_accuracy: 0.5929\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 403s 1s/step - loss: 0.1356 - accuracy: 0.9493 - val_loss: 1.2864 - val_accuracy: 0.5844\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 418s 1s/step - loss: 0.1248 - accuracy: 0.9538 - val_loss: 1.4613 - val_accuracy: 0.5826\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 415s 1s/step - loss: 0.1059 - accuracy: 0.9605 - val_loss: 1.3758 - val_accuracy: 0.5912\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 432s 1s/step - loss: 0.0930 - accuracy: 0.9668 - val_loss: 1.4965 - val_accuracy: 0.5898\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> Fold:4 <<<<<\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 417s 1s/step - loss: 0.6088 - accuracy: 0.6691 - val_loss: 0.6849 - val_accuracy: 0.6441\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 421s 1s/step - loss: 0.3256 - accuracy: 0.8631 - val_loss: 0.7740 - val_accuracy: 0.6361\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 431s 1s/step - loss: 0.2493 - accuracy: 0.8998 - val_loss: 0.8638 - val_accuracy: 0.6226\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 423s 1s/step - loss: 0.2064 - accuracy: 0.9185 - val_loss: 0.9232 - val_accuracy: 0.6129\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 422s 1s/step - loss: 0.1747 - accuracy: 0.9313 - val_loss: 0.9476 - val_accuracy: 0.6177\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 415s 1s/step - loss: 0.1492 - accuracy: 0.9426 - val_loss: 1.0370 - val_accuracy: 0.6129\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 402s 1s/step - loss: 0.1323 - accuracy: 0.9498 - val_loss: 1.1455 - val_accuracy: 0.6077\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 398s 1s/step - loss: 0.1151 - accuracy: 0.9572 - val_loss: 1.1536 - val_accuracy: 0.6144\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 396s 1s/step - loss: 0.0956 - accuracy: 0.9650 - val_loss: 1.4009 - val_accuracy: 0.6098\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 392s 1s/step - loss: 0.0840 - accuracy: 0.9709 - val_loss: 1.4523 - val_accuracy: 0.6036\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> Fold:5 <<<<<\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 388s 994ms/step - loss: 0.6175 - accuracy: 0.6665 - val_loss: 0.6460 - val_accuracy: 0.6536\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 390s 999ms/step - loss: 0.3341 - accuracy: 0.8544 - val_loss: 0.7933 - val_accuracy: 0.6211\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 388s 992ms/step - loss: 0.2459 - accuracy: 0.9024 - val_loss: 0.8419 - val_accuracy: 0.6117\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 387s 989ms/step - loss: 0.2011 - accuracy: 0.9217 - val_loss: 0.9574 - val_accuracy: 0.6030\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 389s 995ms/step - loss: 0.1681 - accuracy: 0.9353 - val_loss: 1.0723 - val_accuracy: 0.6020\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 389s 996ms/step - loss: 0.1433 - accuracy: 0.9451 - val_loss: 1.1934 - val_accuracy: 0.5994\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 385s 985ms/step - loss: 0.1191 - accuracy: 0.9567 - val_loss: 1.2921 - val_accuracy: 0.5949\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 389s 995ms/step - loss: 0.0974 - accuracy: 0.9636 - val_loss: 1.3013 - val_accuracy: 0.5914\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 378s 967ms/step - loss: 0.0840 - accuracy: 0.9696 - val_loss: 1.5369 - val_accuracy: 0.5854\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 380s 973ms/step - loss: 0.0719 - accuracy: 0.9745 - val_loss: 1.6681 - val_accuracy: 0.5892\n",
      ">>>>> Running is done <<<<<\n",
      ">>>>> All folds are done <<<<<\n"
     ]
    }
   ],
   "source": [
    "res2 = []\n",
    "for i in range(1,6):\n",
    "    print(f'>>>>> Fold:{i} <<<<<')\n",
    "    folderName = 'split_' + str(i)\n",
    "    train_filename = folderName + '/' + 'train.tsv'\n",
    "    test_filename = folderName + '/' + 'test.tsv'\n",
    "    test_y_filename = folderName + '/' + 'test_y.tsv'\n",
    "\n",
    "    train_data = pd.read_csv(train_filename,sep='\\t', header=0)\n",
    "    train_data['review']=pd.DataFrame(train_data.review.apply(cleaned_html))\n",
    "    train_data['review']=pd.DataFrame(train_data.review.apply(cleaned1))\n",
    "    train_data['review']=pd.DataFrame(train_data.review.apply(cleaned2))\n",
    "\n",
    "    train_y = train_data['sentiment']\n",
    "    train_features = train_data.copy()\n",
    "    train_features = train_features.drop(['sentiment'],axis=1)\n",
    "\n",
    "    test_data = pd.read_csv(test_filename,sep='\\t', header=0)\n",
    "    test_data['review']=pd.DataFrame(test_data.review.apply(cleaned_html))\n",
    "    test_data['review']=pd.DataFrame(test_data.review.apply(cleaned1))\n",
    "    test_data['review']=pd.DataFrame(test_data.review.apply(cleaned2))\n",
    "\n",
    "    test_features = test_data['review']\n",
    "    # print(test_data.head(5))\n",
    "    # print(test_data.shape)\n",
    "    test_y_data = pd.read_csv(test_y_filename,sep='\\t', header=0)\n",
    "\n",
    "    max_features=5000\n",
    "    tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "    tokenizer.fit_on_texts(train_data['review'].values)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(train_data['review'].values)\n",
    "    X_train = pad_sequences(X_train,maxlen=600)\n",
    "    Y_train = pd.get_dummies(train_data['sentiment']).values\n",
    "    # Y_train = train_data['sentiment']\n",
    "\n",
    "    tokenizer.fit_on_texts(test_data['review'].values)\n",
    "    X_test = tokenizer.texts_to_sequences(test_data['review'].values)\n",
    "    X_test = pad_sequences(X_test,maxlen=600)\n",
    "    Y_test = pd.get_dummies(test_y_data['sentiment']).values\n",
    "    # Y_test = test_y_data['sentiment']\n",
    "\n",
    "    embed_dim = 128\n",
    "    lstm_out = 128\n",
    "    \n",
    "    model2.fit(X_train, Y_train, epochs = 10, batch_size=batch_size,validation_data=(X_test,Y_test),verbose=True)\n",
    "    pred_Y = model2.predict(X_test)\n",
    "    auc = roc_auc_score(Y_test, pred_Y,average='micro')\n",
    "    res2.append(auc)\n",
    "    print('>>>>> Running is done <<<<<')\n",
    "print('>>>>> All folds are done <<<<<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean AUC:0.61725748928\n"
     ]
    }
   ],
   "source": [
    "mean_auc2 = np.mean(res2)\n",
    "\n",
    "print(f'mean AUC:{mean_auc2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a7536edd99629e0d099bb8764624c20ac0930c2990a71a6ca3ab8f7ff47492e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
